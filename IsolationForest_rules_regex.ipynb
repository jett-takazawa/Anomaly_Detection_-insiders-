{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Isolation Forest: Insider Detection with Rules-Based Features\n",
    "## Using Volume/Trade Data, Financial Data, and Regex Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Set visualization style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"Libraries loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load user data with regex features\n",
    "df = pd.read_csv('outputs/output_with_signals.csv')\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nTotal users: {len(df)}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features for anomaly detection\n",
    "FEATURES = [\n",
    "    # Volume/Trade features\n",
    "    'trades_count',\n",
    "    'buy_trades_count',\n",
    "    'sell_trades_count',\n",
    "    'total_volume',\n",
    "    'avg_trade_size',\n",
    "    'total_cash_volume',\n",
    "    \n",
    "    # Financial features\n",
    "    'realized_pnl',\n",
    "    'total_position_value',\n",
    "    'win_rate',\n",
    "    'winning_positions_count',\n",
    "    'closed_positions_count',\n",
    "    \n",
    "    # Behavioral features\n",
    "    'positions_count',\n",
    "    'active_markets_count',\n",
    "    'days_since_first_trade',\n",
    "    'total_markets_count',\n",
    "    \n",
    "    # Regex features (insider signals)\n",
    "    'earnings_count',\n",
    "    'earnings_distinct_issuers',\n",
    "    'other_earnings_markets',\n",
    "    'traded_crypto'\n",
    "]\n",
    "\n",
    "# Extract features\n",
    "df_features = df[FEATURES].copy()\n",
    "\n",
    "# Handle missing values with median\n",
    "df_features = df_features.fillna(df_features.median())\n",
    "\n",
    "print(f\"Total features: {len(FEATURES)}\")\n",
    "print(f\"\\nFeature statistics:\")\n",
    "df_features.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Scale Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use RobustScaler (handles outliers better)\n",
    "scaler = RobustScaler()\n",
    "features_scaled = scaler.fit_transform(df_features)\n",
    "\n",
    "df_scaled = pd.DataFrame(\n",
    "    features_scaled,\n",
    "    columns=df_features.columns,\n",
    "    index=df_features.index\n",
    ")\n",
    "\n",
    "print(f\"Features scaled using RobustScaler\")\n",
    "print(f\"Scaled data shape: {df_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Run Isolation Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Isolation Forest\n",
    "# contamination: expected proportion of anomalies (0.1 = 10%)\n",
    "iso_forest = IsolationForest(\n",
    "    contamination=0.10,\n",
    "    random_state=42,\n",
    "    n_estimators=100\n",
    ")\n",
    "\n",
    "# Fit and predict (-1 for anomalies, 1 for normal)\n",
    "predictions = iso_forest.fit_predict(df_scaled)\n",
    "\n",
    "# Get anomaly scores (lower = more anomalous)\n",
    "anomaly_scores = iso_forest.score_samples(df_scaled)\n",
    "\n",
    "# Add predictions and scores to dataframe\n",
    "df['anomaly_label'] = predictions\n",
    "df['anomaly_score'] = anomaly_scores\n",
    "\n",
    "# Calculate statistics\n",
    "n_anomalies = (predictions == -1).sum()\n",
    "n_normal = (predictions == 1).sum()\n",
    "\n",
    "print(f\"\\nIsolation Forest Results:\")\n",
    "print(f\"  Contamination: 10%\")\n",
    "print(f\"  N Estimators: 100\")\n",
    "print(f\"  Total users: {len(df)}\")\n",
    "print(f\"  Normal users: {n_normal} ({100*n_normal/len(df):.1f}%)\")\n",
    "print(f\"  Anomalies: {n_anomalies} ({100*n_anomalies/len(df):.1f}%)\")\n",
    "print(f\"\\nAnomaly score range: [{anomaly_scores.min():.3f}, {anomaly_scores.max():.3f}]\")\n",
    "print(f\"  Lower scores = more anomalous\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualize with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce to 2D for visualization\n",
    "pca = PCA(n_components=2)\n",
    "features_2d = pca.fit_transform(df_scaled)\n",
    "\n",
    "# Create plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot normal users\n",
    "normal_mask = predictions == 1\n",
    "plt.scatter(features_2d[normal_mask, 0], features_2d[normal_mask, 1],\n",
    "            c='blue', alpha=0.5, s=30, label='Normal')\n",
    "\n",
    "# Plot anomalies\n",
    "anomaly_mask = predictions == -1\n",
    "plt.scatter(features_2d[anomaly_mask, 0], features_2d[anomaly_mask, 1],\n",
    "            c='red', marker='x', s=100, label='Anomalies', linewidths=2)\n",
    "\n",
    "plt.xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%} variance)')\n",
    "plt.ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.1%} variance)')\n",
    "plt.title('Isolation Forest Results (PCA Projection)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('outputs/isolation_forest_pca.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nVisualization saved to outputs/isolation_forest_pca.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Analyze Anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract anomalies\n",
    "anomalies_df = df[df['anomaly_label'] == -1].copy()\n",
    "\n",
    "print(f\"Total anomalies detected: {len(anomalies_df)}\")\n",
    "\n",
    "if len(anomalies_df) > 0:\n",
    "    # Show key features for anomalies\n",
    "    print(f\"\\nAnomalies summary:\")\n",
    "    print(f\"  Users with 2+ earnings issuers: {anomalies_df['other_earnings_markets'].sum()}\")\n",
    "    print(f\"  Users with crypto trades: {anomalies_df['traded_crypto'].sum()}\")\n",
    "    print(f\"  Avg earnings count: {anomalies_df['earnings_count'].mean():.1f}\")\n",
    "    print(f\"  Avg win rate: {anomalies_df['win_rate'].mean():.2f}\")\n",
    "    print(f\"  Avg realized P&L: ${anomalies_df['realized_pnl'].mean():.2f}\")\n",
    "    \n",
    "    # Show top anomalies by score (most anomalous)\n",
    "    print(f\"\\nTop 10 most anomalous users (by anomaly score):\")\n",
    "    display_cols = ['username', 'anomaly_score', 'earnings_count', 'win_rate', \n",
    "                    'realized_pnl', 'total_volume', 'other_earnings_markets', 'traded_crypto']\n",
    "    print(anomalies_df.nsmallest(10, 'anomaly_score')[display_cols].to_string(index=False))\n",
    "else:\n",
    "    print(\"\\nNo anomalies detected - try adjusting contamination parameter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Anomaly Score Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot anomaly score distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Histogram of all scores\n",
    "axes[0].hist(df['anomaly_score'], bins=50, alpha=0.7, edgecolor='black')\n",
    "axes[0].axvline(x=df[df['anomaly_label'] == -1]['anomaly_score'].max(), \n",
    "                color='red', linestyle='--', label='Anomaly Threshold')\n",
    "axes[0].set_xlabel('Anomaly Score')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].set_title('Distribution of Anomaly Scores')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Boxplot comparing normal vs anomalies\n",
    "data_to_plot = [df[df['anomaly_label'] == 1]['anomaly_score'],\n",
    "                df[df['anomaly_label'] == -1]['anomaly_score']]\n",
    "axes[1].boxplot(data_to_plot, labels=['Normal', 'Anomalies'])\n",
    "axes[1].set_ylabel('Anomaly Score')\n",
    "axes[1].set_title('Anomaly Scores: Normal vs Anomalies')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('outputs/isolation_forest_scores.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nScore distribution saved to outputs/isolation_forest_scores.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Feature Importance for Anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(anomalies_df) > 0:\n",
    "    # Compare anomalies vs normal users\n",
    "    normal_df = df[df['anomaly_label'] == 1]\n",
    "    \n",
    "    # Calculate mean differences\n",
    "    comparison = pd.DataFrame({\n",
    "        'Anomalies': anomalies_df[FEATURES].mean(),\n",
    "        'Normal': normal_df[FEATURES].mean()\n",
    "    })\n",
    "    comparison['Difference'] = comparison['Anomalies'] - comparison['Normal']\n",
    "    comparison['Ratio'] = comparison['Anomalies'] / (comparison['Normal'] + 0.001)\n",
    "    comparison = comparison.sort_values('Ratio', ascending=False)\n",
    "    \n",
    "    print(\"\\nFeature comparison (Anomalies vs Normal):\")\n",
    "    print(comparison.head(10).to_string())\n",
    "    \n",
    "    # Plot top differences\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    top_features = comparison.head(10)\n",
    "    x = range(len(top_features))\n",
    "    \n",
    "    ax.barh(x, top_features['Ratio'], alpha=0.7)\n",
    "    ax.set_yticks(x)\n",
    "    ax.set_yticklabels(top_features.index)\n",
    "    ax.set_xlabel('Ratio (Anomalies / Normal)')\n",
    "    ax.set_title('Top 10 Distinguishing Features for Anomalies')\n",
    "    ax.axvline(x=1.0, color='red', linestyle='--', alpha=0.5)\n",
    "    ax.grid(True, alpha=0.3, axis='x')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('outputs/isolation_forest_feature_importance.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nFeature importance saved to outputs/isolation_forest_feature_importance.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(anomalies_df) > 0:\n",
    "    # Select relevant columns for export\n",
    "    export_cols = ['wallet', 'username', 'anomaly_label', 'anomaly_score'] + FEATURES\n",
    "    \n",
    "    # Save anomalies (sorted by most anomalous)\n",
    "    output_path = 'outputs/isolation_forest_anomalies.csv'\n",
    "    anomalies_df.sort_values('anomaly_score')[export_cols].to_csv(output_path, index=False)\n",
    "    print(f\"Saved {len(anomalies_df)} anomalies to: {output_path}\")\n",
    "    \n",
    "    # Save all users with labels and scores\n",
    "    output_path_all = 'outputs/isolation_forest_all_users.csv'\n",
    "    df[export_cols].to_csv(output_path_all, index=False)\n",
    "    print(f\"Saved all {len(df)} users with anomaly labels/scores to: {output_path_all}\")\n",
    "else:\n",
    "    print(\"No anomalies to export\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
